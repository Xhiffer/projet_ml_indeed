{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "3Error on line 136 WebDriverException Message: Failed to decode response from marionette\n",
      "\n",
      "2Error on line 47 InvalidSessionIdException Message: Tried to run command without establishing a connection\n",
      "\n",
      "query_poste développeur\n",
      "\n",
      " query_ville Nantes\n",
      "\n",
      " all_query_contrat permanent\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from pymongo import MongoClient\n",
    "from selenium import webdriver\n",
    "from datetime import date\n",
    "from datetime import date,datetime,timedelta\n",
    "import time as t\n",
    "import re\n",
    "import sys\n",
    "# connect to MongoDB, change the << MONGODB URL >> to reflect your own connection string\n",
    "client = MongoClient('localhost', 27017)\n",
    "try :\n",
    "    db = client['indeed2']\n",
    "except :\n",
    "    db = client.indeed2\n",
    "indeed = db['indeed6']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#liste de toutes les querys dans la bare de recherche indeed\n",
    "#######\n",
    "all_query_poste = ['développeur','business intelligence',\n",
    "                   'data scientist','data science','data analyst','data engineer','data architect',\n",
    "                   'data protection','data manager','data concepteur','big data','devops',\n",
    "                   'web developer','full stack developer','web architect','front end developer','back end developer'] #\n",
    "\n",
    "all_query_ville = ['Nantes','Bordeaux','Île-de-France','Lyon', 'Toulouse']\n",
    "\n",
    "all_query_contrat = ['permanent','fulltime','subcontract','internship',\n",
    "                     'apprenticeship','contract','custom_1','temporary','parttime']\n",
    "#######\n",
    "\n",
    "#lance une boucle sur l'algo de scrapping pour tout nos query \n",
    "#######\n",
    "try :\n",
    "    for query_poste in all_query_poste :\n",
    "        for query_ville in all_query_ville:\n",
    "            for query_contrat in all_query_contrat:\n",
    "                lien = 'https://www.indeed.fr/emplois?q=' + query_poste + '&l=' + query_ville + '&jt=' + query_contrat\n",
    "                browser = webdriver.Firefox(executable_path='geckodriver.exe')\n",
    "                browser.get(lien)\n",
    "                browser.maximize_window()\n",
    "                #change url try\n",
    "                scraploop(browser,query_poste,query_ville,query_contrat,indeed)\n",
    "#######\n",
    "\n",
    "#pour avoir un retour sur plusieurs info durant la situation de l'erreur\n",
    "#######\n",
    "except Exception as e: \n",
    "    print('2Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(e).__name__, e)\n",
    "    print('query_poste ' + query_poste) \n",
    "    print('\\n query_ville ' + query_ville)\n",
    "    print('\\n all_query_contrat ' + query_contrat)\n",
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mail_pop_up quitte l'onglet qui propose d'envoyer notre mail qui pop up dans certaines situations.\n",
    "def mail_pop_up():\n",
    "    try :\n",
    "        CLICK = WebDriverWait(browser, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR , '#popover-close-link')))\n",
    "        CLICK.click()\n",
    "        t.sleep(0.2)\n",
    "    except :\n",
    "        pass\n",
    "\n",
    "#scraploop scrap toutes les pages (1 à 100 pages max) obtenues depuis les query decidé au-dessus.\n",
    "def scraploop(browser,query_poste,query_ville,query_contrat,indeed,time = 0):\n",
    "    #retien le nom de notre page dans le cas où on as plusieur onglet\n",
    "    window_name = browser.window_handles[0]\n",
    "    row = {}\n",
    "    \n",
    "    #quitte le pop_up constant àla 2nd page \n",
    "    if time == 1 :\n",
    "        print('test')\n",
    "        mail_pop_up()\n",
    "    time += 1\n",
    "    \n",
    "    #cherche toutes les offre d'emploit sur la page\n",
    "    try:\n",
    "        post_info =  WebDriverWait(browser, 5).until(EC.presence_of_all_elements_located((By.CLASS_NAME , 'title')))\n",
    "    \n",
    "    #lance la prochaine query si il y a rien\n",
    "    except :\n",
    "        browser.close()\n",
    "        return\n",
    "    \n",
    "    #cherche toutes les ID des offre d'emploit sur la page\n",
    "    ID = browser.find_elements_by_class_name('jobsearch-SerpJobCard')\n",
    "    \n",
    "    #boucle qui scrap toutes les offres de la pages et les implémente dans notre bdd mongodb\n",
    "    for i,post in enumerate(post_info) : \n",
    "        post.location_once_scrolled_into_view\n",
    "        post.click()\n",
    "        \n",
    "        #sleep au cas où (car très rare) quand on clique sur un offre ca nous ouvre les info sur un autre onglet\n",
    "        t.sleep(0.3)\n",
    "        \n",
    "        #Si ouvre nouvelle onglet, on la quitte et relance la page\n",
    "        if len(browser.window_handles) >1 :\n",
    "            print('hi browser.window_handles :)')\n",
    "            browser.switch_to.window(window_name=browser.window_handles[1])\n",
    "            browser.close()\n",
    "            t.sleep(0.2)\n",
    "            browser.switch_to.window(window_name=window_name)\n",
    "            browser.refresh()\n",
    "            mail_pop_up()\n",
    "            scraploop(browser,query_poste,query_ville,query_contrat,indeed,time)\n",
    "        \n",
    "        #extraction de toutes les données\n",
    "        row['query_poste'] = query_poste\n",
    "        row['query_contrat'] = query_contrat\n",
    "        row['query_ville'] = query_ville\n",
    "        row['_id'] = ID[i].get_attribute(\"id\")\n",
    "        row['titre'] = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.ID , 'vjs-jobtitle'))).text\n",
    "        row['nom_de_la_boite'] =  browser.find_element_by_id('vjs-cn').text\n",
    "        row['adresse'] =  browser.find_element_by_id('vjs-loc').text\n",
    "        row['texte'] =  browser.find_element_by_css_selector('#vjs-content').text\n",
    "\n",
    "\n",
    "\n",
    "        try :\n",
    "            iswhat = browser.find_element_by_css_selector('div.jobMetadataHeader-itemWithIcon:nth-child(2)').text\n",
    "            if any(char.isdigit() for char in iswhat) != True :\n",
    "                row['contrat'] =  iswhat\n",
    "                try :  \n",
    "                    row['salaire'] =  browser.find_element_by_css_selector('div.jobMetadataHeader-itemWithIcon:nth-child(3) > span:nth-child(2)').text  #vjs-jobinfo > div:nth-child(3)\n",
    "                except :\n",
    "                    row['salaire'] = ' '\n",
    "                    pass\n",
    "            else :\n",
    "                row['salaire'] =  iswhat\n",
    "        except Exception as e:\n",
    "            row['salaire'] = ' '\n",
    "            pass\n",
    "        try :\n",
    "            date_text = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR , '#vjs-footer'))).text\n",
    "            date_text = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR , '#vjs-footer'))).text\n",
    "            date_value = re.findall(r'\\d+|jour|mois|heure', date_text)\n",
    "            if date_value[1] in 'mois' :\n",
    "                row['date'] = (datetime.today() - timedelta(days= (int(date_value[0])*30.5))).strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "            elif date_value[1] in 'minutes' :\n",
    "                row['date'] = (datetime.today() - timedelta(minutes=int(date_value[0]))).strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "            elif date_value[1] in 'jours' :\n",
    "                row['date'] = (datetime.today() - timedelta(days=int(date_value[0]))).strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "            elif date_value[1] in 'heures' :\n",
    "                row['date'] = (datetime.today() - timedelta(hours=int(date_value[0]))).strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "        except :\n",
    "            pass\n",
    "        try : \n",
    "            row['lien_plus_info'] = browser.find_element_by_css_selector('.ws_label').get_attribute(\"href\")\n",
    "        except :\n",
    "            pass\n",
    "\n",
    "        #si l'_id est unique, crée une nouvelle row, si non implémente les infos qu'on a en plus pour cette _id\n",
    "        try:\n",
    "            indeed.insert_one(row)\n",
    "        except :\n",
    "            #faudrais être plus claire sur les moments de modification (cas où 2/3 choses change en même temps)\n",
    "            #si modification\n",
    "            if row['query_poste'] not in indeed.find({'_id':row['_id']})[0]['query_poste']:\n",
    "                indeed.update({'_id': row['_id']},\n",
    "                               {\"$set\" : {\n",
    "                                           'query_poste': row['query_poste']+', '+indeed.find({'_id':row['_id']})[0]['query_poste']\n",
    "                                      }\n",
    "                                }\n",
    "                            )\n",
    "            if row['query_contrat'] not in indeed.find({'_id':row['_id']})[0]['query_contrat']:\n",
    "                indeed.update({'_id': row['_id']},\n",
    "                               {\"$set\" : {\n",
    "                                           'query_contrat': row['query_contrat']+', '+indeed.find({'_id':row['_id']})[0]['query_contrat']\n",
    "                                      }\n",
    "                                }\n",
    "                            )\n",
    "            if row['query_ville'] not in indeed.find({'_id':row['_id']})[0]['query_ville']:\n",
    "                indeed.update({'_id': row['_id']},\n",
    "                               {\"$set\" : {\n",
    "                                           'query_ville': row['query_ville']+', '+indeed.find({'_id':row['_id']})[0]['query_ville']\n",
    "                                      }\n",
    "                                }\n",
    "                            )\n",
    "            if row['salaire'] != ' ' and row['salaire'] not in indeed.find({'_id':row['_id']})[0]['salaire']:\n",
    "                print(indeed.find({'_id':row['_id']})[0]['salaire'])\n",
    "                indeed.update({'_id': row['_id']},\n",
    "                               {\"$set\" : {\n",
    "                                           'salaire': row['salaire']+', '+indeed.find({'_id':row['_id']})[0]['salaire']\n",
    "                                      }\n",
    "                                }\n",
    "                            )\n",
    "    \n",
    "    #vas à la prochaine page, si pas posible vas au prochain query, car plus de pages \n",
    "    Next = browser.find_elements_by_css_selector('.np')\n",
    "    try :\n",
    "        Next[0].click() if ( time == 1)  else Next[1].click()\n",
    "        return scraploop(browser,query_poste,query_ville,query_contrat,indeed,time)\n",
    "    except Exception as e: \n",
    "        print('3Error on line {}'.format(sys.exc_info()[-1].tb_lineno), type(e).__name__, e)\n",
    "        browser.close()\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
